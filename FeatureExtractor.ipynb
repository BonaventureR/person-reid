{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXKP3Ze5Vwn5"
   },
   "source": [
    "# Feature Extractor\n",
    "\n",
    "The feature extractor within person-reid is an API that shows the embeddings produced by the learned model. In doing so, lets us see the features it finds important and can be built off of a prebuilt model. This notebook serves an example of how the feature extractor is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16178,
     "status": "ok",
     "timestamp": 1607790817813,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "P_WdBXOUzANy",
    "outputId": "a75100d8-faed-4354-dac6-90db094d5ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1607790818909,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "xTd0kdKrzK7b",
    "outputId": "8ba6dd31-793e-46a7-dfe6-64de098288e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/person-reid/deep-person-reid\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/person-reid/deep-person-reid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX810zX1t_9l"
   },
   "outputs": [],
   "source": [
    "!conda create --name torchreid python=3.7\n",
    "!conda activate torchreid\n",
    "!pip install -r requirements.txt\n",
    "!conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHHs1WHjVvr9"
   },
   "outputs": [],
   "source": [
    "from comp_vis_data import CvDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a_0cesaVwM0"
   },
   "outputs": [],
   "source": [
    "import torchreid\n",
    "\n",
    "torchreid.data.register_image_dataset('cvision_dataset', CvDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3585,
     "status": "ok",
     "timestamp": 1607654591209,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "mU9ipqPiWC_t",
    "outputId": "688f5878-bde1-46f9-dd81-ebf23a0df602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "self.dataset_dir /content/drive/My Drive/person-reid/deep-person-reid/reid-data/data\n",
      "=> Loaded CvDataSet\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     2 |      169 |         7\n",
      "  query    |     2 |       39 |         6\n",
      "  gallery  |     2 |      130 |         7\n",
      "  ----------------------------------------\n",
      "self.dataset_dir /content/drive/My Drive/person-reid/deep-person-reid/reid-data/data\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['cvision_dataset']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root='reid-data',\n",
    "    sources='market1501',\n",
    "    targets='cvision_dataset',\n",
    "    height=256,\n",
    "    width=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0RJ2FbWCc3"
   },
   "source": [
    "Build off a pre-built model, in this case we use the duke 256x128 model to make feature predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1607791265483,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "Dq1Eii_qtcRA",
    "outputId": "b7774273-1521-4341-a411-43535b41c2f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/person-reid/deep-person-reid/pre-trained-models/osnet_ibn_x1_0_duke_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd() + '/pre-trained-models/osnet_ibn_x1_0_duke_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1441980,
     "status": "ok",
     "timestamp": 1607792979395,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "1cpQLVDdXxq5",
    "outputId": "ca2369f8-9b11-45c5-e5b4-b558687d24b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370128159/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "Creating directory \"/content/drive/My Drive/person-reid/deep-person-reid/testing_data/market1501\"\n",
      "Downloading Market1501 dataset to \"/content/drive/My Drive/person-reid/deep-person-reid/testing_data/market1501\"\n",
      "* url=\"http://188.138.127.15:81/Datasets/Market-1501-v15.09.15.zip\"\n",
      "* destination=\"/content/drive/My Drive/person-reid/deep-person-reid/testing_data/market1501/Market-1501-v15.09.15.zip\"\n",
      "...100%, 145 MB, 10169 KB/s, 14 seconds passed\n",
      "Extracting \"/content/drive/My Drive/person-reid/deep-person-reid/testing_data/market1501/Market-1501-v15.09.15.zip\"\n",
      "Market1501 dataset is ready\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY\n",
      "To: /root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\n",
      "10.9MB [00:00, 168MB/s]\n",
      "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "/content/drive/My Drive/person-reid/deep-person-reid/torchreid/utils/tools.py:42: UserWarning: No file found at \"path\"\n",
      "  warnings.warn('No file found at \"{}\"'.format(fpath))\n",
      "Visualizing activation maps for market1501 ...\n",
      "- done batch 10/34\n",
      "- done batch 20/34\n",
      "- done batch 30/34\n"
     ]
    }
   ],
   "source": [
    "!python tools/visualize_actmap.py \\\n",
    "--root testing_data/ \\\n",
    "-d market1501 \\\n",
    "-m osnet_x1_0 \\\n",
    "--weights path \\\n",
    "--save-dir log/visactmap_osnet_x1_0_market1501xDuke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK1OBVq_WKQz"
   },
   "source": [
    "This model uses the osnet model with the pretrained model on market1501 with softmax and label smoothing to query extract features from the list of data we provide from our dataset. (Our data is located within cv_dataset, we use the query function to see what the embeddings it produces are)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1607654229421,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "6Rr-6FF-Zx6M",
    "outputId": "dde89e8a-5720-4706-fbf5-6119a98db25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Model: osnet_x1_0\n",
      "- params: 2,193,616\n",
      "- flops: 978,878,352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/person-reid/deep-person-reid/torchreid/utils/tools.py:42: UserWarning: No file found at \"osnet_ibn_x1_0_market1501_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth\"\n",
      "  warnings.warn('No file found at \"{}\"'.format(fpath))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "from torchreid.utils import FeatureExtractor\n",
    "\n",
    "extractor = FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    model_path='osnet_ibn_x1_0_market1501_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth',\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "image_list = [\n",
    "    './reid-data/data/cv_dataset/query/0006/0006_c2s1_10.jpg',\n",
    "]\n",
    "\n",
    "features = extractor(image_list)\n",
    "print(features.shape) # output (5, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3rwdwE8Wa1R"
   },
   "source": [
    "This is the list of features that it learns in the embedding layer that uses euclidean distance to find similarity in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1607654238378,
     "user": {
      "displayName": "Bonaventure Raj",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqjcUxZsLP4yW5xE0rZkh6rD6pAr7JvJklQpXf=s64",
      "userId": "03021209118316038736"
     },
     "user_tz": 300
    },
    "id": "XzBIyb_5qBal",
    "outputId": "f78d108f-0912-499b-ab9e-4913f07f3833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.2457e-01, 2.6057e+00, 0.0000e+00, 0.0000e+00, 6.5838e-01, 5.1139e-01,\n",
       "         0.0000e+00, 9.7932e-01, 6.2505e-01, 1.2671e-01, 0.0000e+00, 1.8568e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.4102e+00, 0.0000e+00, 1.2224e+00, 1.3301e+00,\n",
       "         1.5735e-01, 0.0000e+00, 2.1626e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.8913e-01, 1.3931e+00, 1.7769e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5195e+00, 1.5002e+00, 0.0000e+00, 5.6601e-01, 1.4144e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.6008e+00, 1.8294e+00, 3.6606e+00, 1.2931e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6254e-01, 1.1560e+00, 2.6188e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4930e-01, 1.8764e-01, 7.2190e-01,\n",
       "         3.3500e+00, 2.3105e+00, 1.1536e+00, 2.1683e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 9.0640e-01, 0.0000e+00, 2.8864e-01, 1.6341e+00, 0.0000e+00,\n",
       "         3.8130e+00, 7.1817e-01, 0.0000e+00, 0.0000e+00, 2.3098e-03, 3.9842e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0892e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.1193e-01, 1.4077e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.5970e+00, 5.7714e-01, 0.0000e+00, 0.0000e+00, 4.8943e-01,\n",
       "         5.7647e-01, 0.0000e+00, 2.2906e+00, 0.0000e+00, 6.4974e-01, 9.2961e-01,\n",
       "         1.3040e+00, 1.9666e+00, 3.0935e+00, 8.8076e-01, 1.0973e-01, 0.0000e+00,\n",
       "         4.4631e-01, 1.9747e+00, 1.8838e+00, 0.0000e+00, 1.3041e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0226e+00, 0.0000e+00, 5.4052e-01, 2.0878e+00, 1.2423e+00,\n",
       "         1.8260e+00, 0.0000e+00, 0.0000e+00, 2.7054e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.2208e-01, 1.2127e+00, 5.8421e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.5971e-03, 0.0000e+00, 5.3862e-03, 0.0000e+00, 3.0025e-01, 9.8672e-01,\n",
       "         3.6696e+00, 0.0000e+00, 7.5807e-01, 2.5936e+00, 1.0730e+00, 1.3014e+00,\n",
       "         3.7031e-01, 9.4375e-01, 2.6327e+00, 1.8958e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.9456e+00, 0.0000e+00, 1.0345e+00, 1.2371e+00, 0.0000e+00, 6.7495e-01,\n",
       "         2.4453e+00, 0.0000e+00, 4.6731e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.2955e+00, 5.9664e-01, 9.7807e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.1580e+00, 3.8265e+00, 8.8313e-01, 4.1128e-01, 1.2732e+00, 0.0000e+00,\n",
       "         1.4245e+00, 5.6695e-01, 2.8678e+00, 0.0000e+00, 5.6277e-01, 3.5838e-01,\n",
       "         0.0000e+00, 5.4693e-01, 0.0000e+00, 1.4823e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.1706e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6913e-01, 2.7839e-01,\n",
       "         4.4458e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6997e+00, 1.0233e+00,\n",
       "         7.9224e-02, 1.5774e+00, 9.1305e-01, 1.6236e+00, 4.2116e-01, 1.8881e+00,\n",
       "         1.9562e-01, 2.8994e+00, 1.4219e-01, 0.0000e+00, 0.0000e+00, 1.0172e+00,\n",
       "         1.9610e-01, 0.0000e+00, 9.9513e-01, 0.0000e+00, 1.1718e+00, 1.7868e+00,\n",
       "         0.0000e+00, 3.4173e+00, 2.2575e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.7019e-01, 2.8147e+00, 0.0000e+00, 1.4357e+00, 0.0000e+00, 2.7018e+00,\n",
       "         1.6973e+00, 7.3310e-01, 4.7660e-01, 4.9997e-01, 2.5872e+00, 0.0000e+00,\n",
       "         1.7618e+00, 0.0000e+00, 2.2860e-01, 8.0405e-01, 1.0236e+00, 0.0000e+00,\n",
       "         7.6925e-01, 1.1655e+00, 1.2256e+00, 5.3940e-01, 1.1073e+00, 0.0000e+00,\n",
       "         8.4127e-01, 0.0000e+00, 1.9868e+00, 0.0000e+00, 0.0000e+00, 3.4920e+00,\n",
       "         1.3633e+00, 0.0000e+00, 9.7171e-01, 1.9751e+00, 6.5012e-01, 0.0000e+00,\n",
       "         1.1827e+00, 0.0000e+00, 1.3799e+00, 0.0000e+00, 2.5475e+00, 1.1858e+00,\n",
       "         7.5027e-01, 8.2956e-01, 0.0000e+00, 0.0000e+00, 1.7493e+00, 7.6121e-01,\n",
       "         0.0000e+00, 0.0000e+00, 7.7021e-01, 1.7861e+00, 1.0474e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.8802e-01, 7.7947e-01, 1.6535e+00, 2.5333e-01, 1.4136e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5346e+00, 0.0000e+00, 1.5182e+00,\n",
       "         1.4467e-01, 0.0000e+00, 1.2310e+00, 0.0000e+00, 7.1910e-01, 8.2776e-01,\n",
       "         2.0850e+00, 0.0000e+00, 2.7550e+00, 1.0764e+00, 1.6356e-01, 4.0819e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.4383e+00, 5.8322e-01, 0.0000e+00, 8.0347e-01,\n",
       "         0.0000e+00, 2.4953e-01, 0.0000e+00, 0.0000e+00, 1.4043e+00, 3.6322e-01,\n",
       "         9.8755e-01, 2.6520e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.9734e+00, 2.0690e+00, 1.8738e+00, 0.0000e+00, 0.0000e+00, 1.3164e+00,\n",
       "         4.0779e-01, 1.2362e-01, 0.0000e+00, 2.7072e+00, 1.2355e+00, 2.3751e+00,\n",
       "         2.7098e+00, 0.0000e+00, 0.0000e+00, 2.1755e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.0683e-01, 0.0000e+00, 0.0000e+00, 1.4921e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.6299e+00, 0.0000e+00, 1.6145e+00, 2.0414e+00, 0.0000e+00, 1.3422e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1821e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.8017e+00, 0.0000e+00, 2.0986e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 4.8935e-01, 1.8664e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.0384e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7184e-01, 1.4223e-01,\n",
       "         1.8558e+00, 0.0000e+00, 0.0000e+00, 7.5584e-01, 0.0000e+00, 8.4097e-02,\n",
       "         0.0000e+00, 3.1706e+00, 0.0000e+00, 2.3535e+00, 3.4377e-01, 2.8080e+00,\n",
       "         8.9653e-01, 0.0000e+00, 0.0000e+00, 2.9134e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.7842e+00, 0.0000e+00, 3.7518e-01, 0.0000e+00, 0.0000e+00, 8.5038e-01,\n",
       "         0.0000e+00, 1.7647e-01, 0.0000e+00, 6.2794e-01, 9.4346e-01, 0.0000e+00,\n",
       "         1.7143e-01, 3.0862e-01, 1.0456e+00, 1.0185e+00, 0.0000e+00, 8.2838e-01,\n",
       "         0.0000e+00, 0.0000e+00, 7.5529e-01, 0.0000e+00, 1.1203e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.1283e+00, 0.0000e+00, 1.8481e+00, 1.3025e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.1147e+00, 1.5943e+00, 0.0000e+00, 8.3743e-01,\n",
       "         4.5837e-01, 1.9386e+00, 6.8267e-01, 6.2678e-02, 1.8628e+00, 0.0000e+00,\n",
       "         5.4120e+00, 0.0000e+00, 4.1688e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.7680e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3219e-01, 0.0000e+00,\n",
       "         6.3427e-01, 2.4709e-01, 0.0000e+00, 0.0000e+00, 7.8138e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.1931e-01, 0.0000e+00, 0.0000e+00, 1.8621e+00,\n",
       "         6.7615e-01, 0.0000e+00, 1.4622e+00, 3.6468e-01, 0.0000e+00, 1.0308e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0076e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 3.4514e-01, 2.1970e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0465e-01, 4.9687e-01, 2.6406e+00,\n",
       "         2.0189e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3036e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.1618e+00, 0.0000e+00, 7.5681e-01, 0.0000e+00,\n",
       "         3.9992e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0750e+00, 9.8200e-01, 0.0000e+00, 2.1238e-01, 4.4973e+00, 2.7129e-01,\n",
       "         6.3177e-01, 3.6541e-01, 1.1281e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.4044e-01, 2.0081e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kHXxSoQqOdJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOtydu6WEwp1msp+VwLk27W",
   "collapsed_sections": [],
   "name": "FeatureExtractor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
